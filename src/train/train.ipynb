{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from preprocessor import Preprocessor\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessor = Preprocessor()\n",
    "\n",
    "data = pd.read_csv(\"../../data/wikipedia.csv\")\n",
    "# clean out where text is NaN\n",
    "data = data[data.text.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(359, 300)\n"
     ]
    }
   ],
   "source": [
    "doc_vectors = np.array([train_preprocessor.vectorize(text) for text in data.text])\n",
    "print(doc_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.constant(doc_vectors, shape=(1,359,300))\n",
    "labels = tf.constant(data.label.to_numpy(), shape=(1,359,1))\n",
    "\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((features,labels))\n",
    "features_dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "labels_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "\n",
    "train_dataset = tf.data.Dataset.zip((features_dataset, labels_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(doc_vectors, data.label, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(300,)),  # input shape required\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def get_new_y(predictions, labels):\n",
    "  new_y = []\n",
    "  for idx, val in enumerate(predictions.numpy()):\n",
    "      label = labels[idx].numpy()\n",
    "      relevant_data = []\n",
    "      for idx2, value in enumerate(labels.numpy()):\n",
    "          if(value == label and idx2 != idx):\n",
    "              relevant_data.append(predictions[idx2])\n",
    "      new_y.append(relevant_data[random.randint(0,len(relevant_data)-1)])\n",
    "  return new_y\n",
    "\n",
    "def loss(model, x, y, training):\n",
    "  # training=training is needed only if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  y_ = model(x, training=training)\n",
    "  new_y = get_new_y(y_, y)\n",
    "\n",
    "  return loss_object(y_true=new_y, y_pred=y_)\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets, training=True)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(359, 300)\n",
      "Epoch 000: Loss: 0.110, MAE: 0.22\n",
      "(359, 300)\n",
      "Epoch 001: Loss: 0.102, MAE: 0.217\n",
      "(359, 300)\n",
      "Epoch 002: Loss: 0.090, MAE: 0.215\n",
      "(359, 300)\n",
      "Epoch 003: Loss: 0.092, MAE: 0.196\n",
      "(359, 300)\n",
      "Epoch 004: Loss: 0.094, MAE: 0.196\n",
      "(359, 300)\n",
      "Epoch 005: Loss: 0.085, MAE: 0.189\n",
      "(359, 300)\n",
      "Epoch 006: Loss: 0.074, MAE: 0.175\n",
      "(359, 300)\n",
      "Epoch 007: Loss: 0.070, MAE: 0.194\n",
      "(359, 300)\n",
      "Epoch 008: Loss: 0.067, MAE: 0.179\n",
      "(359, 300)\n",
      "Epoch 009: Loss: 0.072, MAE: 0.171\n"
     ]
    }
   ],
   "source": [
    "## Note: Rerunning this cell uses the same model variables\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "  epoch_accuracy = tf.keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "  # Training loop - using batches of 32\n",
    "  for x, y in train_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value, grads = grad(model, x, y)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Track progress\n",
    "    epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "    # Compare predicted label to actual label\n",
    "    # training=True is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(x, training=True)\n",
    "    new_y = get_new_y(predictions, y)\n",
    "    epoch_accuracy.update_state(new_y, predictions)\n",
    "\n",
    "  # End epoch\n",
    "  train_loss_results.append(epoch_loss_avg.result())\n",
    "  train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "  print(\"Epoch {:03d}: Loss: {:.3f}, MAE: {:.3}\".format(epoch,epoch_loss_avg.result(),epoch_accuracy.result()))"
   ]
  }
 ]
}